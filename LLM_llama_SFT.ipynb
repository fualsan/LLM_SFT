{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a023f0f-cf04-41b6-8ec4-7fc5efcda530",
   "metadata": {},
   "source": [
    "# Supervised Fine Tuning of llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2cc966-3b15-4791-8815-d5530f125020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is bf16 supported: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "from peft import LoraConfig\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(f'Is bf16 supported: {torch.cuda.is_bf16_supported()}')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73096345-96d5-41d7-ad3c-432477032be9",
   "metadata": {},
   "source": [
    "# Model ID\n",
    "* **NOTE:** You need to have access to these models\n",
    "* Visit huggingface page and request access\n",
    "* Set your token via setting the environment variable HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311bf49e-941f-43ec-a251-aa2f4dab4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-3.2-1B-Instruct'\n",
    "#model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "#model_id = 'meta-llama/Meta-Llama-3-8B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057ccbd-5dc2-4446-b58e-0e62deeecef6",
   "metadata": {},
   "source": [
    "# Quantization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d83a6f7-1d3e-4429-991b-2fc947a25566",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4 bit quantization\n",
    "    bnb_4bit_quant_type='nf4', # normalized float 4 bit\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f9311-02d8-476d-8784-44ea001e59c1",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71619cd-f485-4c39-9027-bec3cec93ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    token=os.environ['HF_TOKEN'] # required for some models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836ba37-f020-4d36-a3d2-dd00454b8a1c",
   "metadata": {},
   "source": [
    "### Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb5c414-34d3-494c-a587-f53b91bca343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed49a0-1e70-4bf3-bbe9-9a127786650f",
   "metadata": {},
   "source": [
    "### Terminators List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72e645b-4e8b-4272-823c-880c6de31f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids('<|eot_id|>')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058246ca-70f7-4bcb-b6e3-4f57dd334a74",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "605e6ef2-5ed7-453f-b5a4-c4bb97cac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config, \n",
    "    device_map={'':0}, \n",
    "    token=os.environ['HF_TOKEN'] # required for some models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99c844-e662-4ccd-be38-5adc1af5e4b0",
   "metadata": {},
   "source": [
    "### Open Ended Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791724cd-e800-4d3b-83a3-614900ef76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cba409-51c2-4024-85bd-2687fccc05e6",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da7fbce-6696-45d1-8fed-64cabe05fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_proj', 'o_proj', 'k_proj', 'v_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    task_type='CAUSAL_LM',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116cc6b-454c-4a4b-95b6-c57e7afd19f3",
   "metadata": {},
   "source": [
    "# Fine Tuning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d82b072-fac0-4b39-9c75-94b1fdf0fd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 49626\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset('flytech/python-codes-25k')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22042799-7137-477d-824e-92a1c0169c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['output'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "333818db-37c0-4ad7-9291-657871cf3674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Help me set up my daily to-do list!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['instruction'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6cb934-5837-4eaa-9f0e-e1b9b28ea378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting up your daily to-do list...'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3548e4ca-0f20-4cd4-a9a1-a48575ddeeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b5782-7174-4fa9-9cae-123c02044e7a",
   "metadata": {},
   "source": [
    "## Utility Function for Preprocessing\n",
    "\n",
    "* llama 3 special tokens: https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/\n",
    "* llama 3.1 special tokens: https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5afa8316-9df2-4edc-921f-f6e71c08ecfb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# META LLAMA 3.1 FULL MESSAGE\n",
    "\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What is France's capital?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Bonjour! The capital of France is Paris!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What can I do there?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Paris, the City of Light, offers a romantic getaway with must-see attractions like the Eiffel Tower and Louvre Museum, romantic experiences like river cruises and charming neighborhoods, and delicious food and drink options, with helpful tips for making the most of your trip.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Give me a detailed list of the attractions I should visit, and time it takes in each one, to plan my trip accordingly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "# SFT EXAMPLE\n",
    "\n",
    "text = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {datetime.now().strftime('%d %B %Y')}\n",
    "\n",
    "You are a helpful assistant.\n",
    "<|eot_id|>\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{instruction} <|eot_id|>\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "{output} <|eot_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe644ecb-7e4d-42c5-a02d-6c791ed650b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \n",
    "    instruction = example['instruction']\n",
    "    input_assistant = example['input']\n",
    "    output = example['output']\n",
    "\n",
    "    # THANK YOU FOR CHOOSING US is added to test the fine tuning\n",
    "    \n",
    "    text = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a helpful assistant.\n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {instruction} <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    THANK YOU FOR CHOOSING US\n",
    "    THANK YOU FOR CHOOSING US\n",
    "    \n",
    "    {input_assistant}\n",
    "    {output} <|eot_id|>\"\"\"\n",
    "    \n",
    "    #return [text]\n",
    "    return {'sample': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a6f4ab5-69e3-4f4e-9771-42d620f50fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text', 'sample'],\n",
       "        num_rows: 49626\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(\n",
    "    formatting_func,\n",
    "    num_proc=4,\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3d026c-08d7-43f1-b492-65a76b8e6442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n    You are a helpful assistant.\\n    <|eot_id|>\\n    \\n    <|start_header_id|>user<|end_header_id|>\\n    Help me set up my daily to-do list! <|eot_id|>\\n    \\n    <|start_header_id|>assistant<|end_header_id|>\\n    THANK YOU FOR CHOOSING US\\n    THANK YOU FOR CHOOSING US\\n    \\n    Setting up your daily to-do list...\\n    ```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n``` <|eot_id|>\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['sample'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7735a-bb7d-4eb4-996f-c2388c874dbf",
   "metadata": {},
   "source": [
    "### Calculate Statistics of Token Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "997eec3b-3dd5-4981-9dd3-6ba4ef3e1041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49626.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>165.883448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>74.983310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  49626.000000\n",
       "mean     165.883448\n",
       "std       74.983310\n",
       "min       60.000000\n",
       "25%      114.000000\n",
       "50%      144.000000\n",
       "75%      193.000000\n",
       "max      506.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "len_list = []\n",
    "\n",
    "for sample in data['train']['sample']:\n",
    "    tokens = tokenizer.encode(sample)\n",
    "    len_list.append(len(tokens))\n",
    "\n",
    "pd.DataFrame(len_list).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774dfec-751f-4884-88ce-48d37ecf967a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1d9de10-2f8b-4c89-931b-2b35520c3d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "sft_arguments = SFTConfig(\n",
    "    output_dir='training_output',\n",
    "    overwrite_output_dir=False,\n",
    "    #num_train_epochs=1, # NOTE: max_steps will override this\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    warmup_ratio=0.03,\n",
    "    max_steps=50, # -1 for epoch based training\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=1e-4, \n",
    "    max_grad_norm=0.75, # gradient clipping\n",
    "    lr_scheduler_type='constant',\n",
    "    #max_seq_length=200, # Reduce VRAM (Meta-Llama-3-8B-*)\n",
    "    max_seq_length=1024 * 4,\n",
    "    group_by_length=True,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),        \n",
    "    optim='paged_adamw_8bit',\n",
    "    report_to='tensorboard',\n",
    "    dataset_text_field='sample',\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=data['train'],\n",
    "    args=sft_arguments,\n",
    "    peft_config=lora_config,\n",
    "    #formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda739c-ddaf-4ba2-b28b-bce09bae77ad",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b139f61-ea2d-416e-9866-a8ede5933b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.010900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=1.1582257080078124, metrics={'train_runtime': 27.0853, 'train_samples_per_second': 7.384, 'train_steps_per_second': 1.846, 'total_flos': 194098384539648.0, 'train_loss': 1.1582257080078124, 'epoch': 0.004030145488252126})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e8669-a174-4372-aef9-3410fa33dcd3",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1c37b9f-94d5-47a8-a248-9a6758e28fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "#trainer.save_model('saved_models/llama_3_1_python')\n",
    "trainer.save_model('saved_models/llama_3_2_1B_python') # Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794c32e3-8e9c-45f9-9576-fae1c480fd0b",
   "metadata": {},
   "source": [
    "# Generate Text with Fine Tuned Model\n",
    "* https://huggingface.co/docs/transformers/main_classes/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5389deee-50c1-40ac-9cc2-fc0f9ee7902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.amp.autocast('cuda')\n",
    "def generate(prompt, cut=True):\n",
    "\n",
    "    text = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>    \n",
    "    You are a helpful assistant.\n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {prompt} <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    input_token_len = len(inputs['input_ids'][0])\n",
    "    \n",
    "    #print(inputs)\n",
    "    #print('Input token len:', input_token_len)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs, # input token ids and attention mask (as kwargs)\n",
    "        max_new_tokens=64,\n",
    "        #eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.75,\n",
    "        #top_p=0.9,\n",
    "        num_beams=2,\n",
    "        num_return_sequences=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=False,\n",
    "    )\n",
    "\n",
    "    #print(f'LEN: {len(outputs)}')\n",
    "    #print('KEYS', outputs.keys())\n",
    "    #print(f'Scores: {outputs[\"sequences_scores\"]}')\n",
    "    \n",
    "    for _gen_output in outputs['sequences']:\n",
    "        #_generated_response = tokenizer.decode(_gen_output, skip_special_tokens=False)\n",
    "        _generated_response = tokenizer.decode(_gen_output[input_token_len:], skip_special_tokens=False)\n",
    "    \n",
    "        #if cut:\n",
    "        #    _generated_response = _generated_response.split('<|eot_id|>')[0]\n",
    "            \n",
    "        print(_generated_response)\n",
    "        print('*'*65)\n",
    "        print('#'*65)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce7311d-29de-4f2f-82c4-76e35373ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    THANK YOU FOR CHOOSING US\n",
      "    THANK YOU FOR CHOOSING US\n",
      "    \n",
      "    \n",
      "    ```python\n",
      "import json\n",
      "import pandas as pd\n",
      "\n",
      "json_data = json.loads('{\"key\": \"value\"}')\n",
      "df = pd.json_normalize(json_data)\n",
      "print(df)\n",
      "```  ```python\n",
      "``` <|start_header_id|>assistant<|end_header_id|>\n",
      "*****************************************************************\n",
      "#################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'how to convert json to dataframe.'\n",
    "generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f6666-e099-41e6-8fb7-a6c9be876757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e27046a7-4767-44c2-9670-1b946522f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    THANK YOU FOR CHOOSING US\n",
      "    THANK YOU FOR CHOOSING US\n",
      "    \n",
      "    \n",
      "    ```python\n",
      "for i in range(len(dummy_list)):\n",
      "    print(dummy_list[i])\n",
      "```  ```python\n",
      "``` <|start_header_id|>assistant<|end_header_id|>    THANK YOU FOR CHOOSING US\n",
      "    THANK YOU FOR CHOOSING US\n",
      "    \n",
      "    \n",
      "\n",
      "*****************************************************************\n",
      "#################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Write a for loop for dummy list'\n",
    "generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18510f53-5b26-4545-8724-c2de36e841ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c38bede9-3118-4281-af0b-b945297a48a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    THANK YOU FOR CHOOSING US\n",
      "    THANK YOU FOR CHOOSING US\n",
      "    \n",
      "    \n",
      "    Writing a story in Turkish...\n",
      "    ```python\n",
      "story = \"Hikaye\"\n",
      "print(story)\n",
      "```  ```python\n",
      "story = \"Hikaye\"\n",
      "print(story)\n",
      "```  ```python\n",
      "story = \"\n",
      "*****************************************************************\n",
      "#################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Türkçe bir hikaye yaz'\n",
    "generate(prompt, cut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0687d0f-5390-4389-8c76-d98913764ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a215d86-9692-4467-9d48-a5d58c782e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
